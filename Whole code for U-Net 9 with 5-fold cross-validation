import tensorflow as tf
import os
import random
import numpy as np
from tqdm import tqdm
from skimage.io import imread, imshow
from skimage import img_as_ubyte, transform, util
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn import metrics
import matplotlib.pyplot as plt
from PIL import Image
import csv
import pandas as pd

# Ensure reproducibility
os.environ['TF_DETERMINISTIC_OPS'] = '1'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

np.random.seed(42)
random.seed(42)
tf.random.set_seed(42)

tf.config.threading.set_intra_op_parallelism_threads(1)
tf.config.threading.set_inter_op_parallelism_threads(1)

SIZE = 800
IMG_CHANNELS = 1

TRAIN_PATH = '/content/drive/MyDrive/U-net/All 200 images refined/'

# os.walk is used to get a list of subdirectories within the TRAIN_PATH and TEST_PATH directories,
# and the resulting subdirectory names are stored in train_ids and test_ids, respectively.
train_ids = next(os.walk(TRAIN_PATH))[1]   # [1] retrieves only the subdirectories within the current directory

print(train_ids)
print(len(train_ids))

# Define metrics
accuracy_metric = tf.keras.metrics.BinaryAccuracy()
precision_metric = tf.keras.metrics.Precision()
recall_metric = tf.keras.metrics.Recall()

def f1_score(y_true, y_pred):
    y_true = tf.keras.backend.cast(y_true, 'float32')
    y_pred = tf.keras.backend.cast(y_pred, 'float32')
    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))
    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))
    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))

    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())
    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())

    f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
    return f1


def IoU(y_true, y_pred):
    # Clip predictions and ground truths to binary values (0 or 1)
    y_true = tf.keras.backend.cast(y_true, 'float32')
    y_pred = tf.keras.backend.cast(y_pred, 'float32')

    y_true = tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1))
    y_pred = tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1))

    # Calculate the intersection and union
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection

    # Calculate IoU
    iou = intersection / (union + tf.keras.backend.epsilon())

    return iou

import numpy as np

def random_brightness_contrast(image, brightness_range=(0.5, 1.5), contrast_range=(0.5, 1.5), seed=None):
    # Convert to float32 for calculations
    image = image.astype(np.float32)

    # Set random seed for reproducibility
    if seed is not None:
        np.random.seed(seed)

    # Apply random contrast adjustment
    contrast_factor = np.random.uniform(*contrast_range)
    mean = np.mean(image)
    image = (image - mean) * contrast_factor + mean

    # Apply random brightness adjustment
    brightness_factor = np.random.uniform(*brightness_range)
    image = image * brightness_factor

    # Clip to [0, 255] and convert back to uint8
    image = np.clip(image, 0, 255).astype(np.uint8)

    return image

### Train Images ###

# store the preprocessed images and their corresponding binary masks
# The dtype argument is set to np.uint8 for X_train and np.bool for Y_train to reduce memory usage.
X_train = np.zeros((len(train_ids), SIZE, SIZE, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(train_ids), SIZE, SIZE, 1), dtype=bool)

print('Processing training data')

# Iterate through all the training IDs
for index, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):
    # Construct the paths for the image and mask
    img_path = f"{TRAIN_PATH}{id_}/image/{id_}.jpg"
    mask_path = f"{TRAIN_PATH}{id_}/mask/{id_}.png"

    # Load and normalize the image
    image = imread(img_path, as_gray=True)
    if image.max() <= 1.0:
        image = image * 255  # Convert to [0, 255] scale
    image = np.uint8(image)
    image = random_brightness_contrast(image)  # Apply random adjustments
    image = np.expand_dims(image, axis=-1)  # Ensure image has 3 dimensions
    X_train[index] = image

    # Load and prepare the mask
    mask = imread(mask_path, as_gray=True)
    mask = mask > 0  # Convert grayscale to binary mask
    mask = np.expand_dims(mask, axis=-1)  # Ensure mask has 3 dimensions
    Y_train[index] = mask


print("X_train length: ", len(X_train), "X_train dtype:", X_train.dtype)
print("Y_train length: ", len(Y_train), "Y_train dtype:", Y_train.dtype)

NUM_FILTERS = 24
DROPOUT_RATE = 0.2
LEARNING_RATE = 0.0005
CLIPVALUE = 1
BATCH_SIZE = 4

kf = KFold(n_splits=5, shuffle=True, random_state=42)

Accuracy = []
Precision = []
Recall = []
F1_score = []
IoU_scores = []

start_fold = 1
current_fold = 1

for train_index, test_index in kf.split(X_train):
    if current_fold < start_fold:
        current_fold += 1
        continue

    fold = current_fold
    print(f"Fold {current_fold}:")

    # Split the data
    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]
    Y_train_fold, Y_test_fold = Y_train[train_index], Y_train[test_index]
    X_train_120, X_val, Y_train_120, Y_val = train_test_split(X_train_fold, Y_train_fold, test_size=40/160, random_state=42, shuffle=True)


    # Augment only the actual training set
    X_train_aug = []
    Y_train_aug = []

    for n in tqdm(range(len(X_train_120))):
        augmented_images = []
        augmented_masks = []

        for angle in [0, 90, 180, 270]:
            augmented_img_rotate = transform.rotate(X_train_120[n], angle, mode='reflect')
            augmented_mask_rotate = (transform.rotate(Y_train_120[n], angle, mode='reflect') > 0.5).astype(bool)


            augmented_images.append(img_as_ubyte(augmented_img_rotate))
            augmented_masks.append(img_as_ubyte(augmented_mask_rotate))

        # Horizontal flip
        augmented_images.extend([img_as_ubyte(np.fliplr(img)) for img in augmented_images])
        augmented_masks.extend([img_as_ubyte(np.fliplr(mask)) for mask in augmented_masks])

        for img in augmented_images:
            if img.max() <= 1.0:
                img = img * 255
            img = np.uint8(img)
            img = random_brightness_contrast(img)
            img = np.squeeze(img)
            X_train_aug.append(img)

        Y_train_aug.extend(augmented_masks)

    X_train_aug = np.expand_dims(np.array(X_train_aug, dtype=np.uint8), axis=-1)
    Y_train_aug = np.array(Y_train_aug, dtype=bool)


    ## Val images ##
    for n in tqdm(range(len(X_val))):
        Val_image = X_val[n]
        if Val_image.max() <= 1.0:
            Val_image = Val_image * 255  # Convert to [0, 255] scale
        Val_image = np.uint8(Val_image)
        Val_image = random_brightness_contrast(Val_image, seed=42)  # Apply random adjustments
        X_val[n] = Val_image

    ## Test images ##
    for n in tqdm(range(len(X_test_fold))):
        test_image = X_test_fold[n]
        if test_image.max() <= 1.0:
            test_image = test_image * 255  # Convert to [0, 255] scale
        test_image = np.uint8(test_image)
        test_image = random_brightness_contrast(test_image, seed=42)  # Apply random adjustments
        X_test_fold[n] = test_image

    print(f"Number of training samples after augmentation_K{current_fold}: {len(X_train_aug)}", " Shape:", np.shape(X_train_aug))
    print(f"Number of training masks after augmentation_K{current_fold}: {len(Y_train_aug)}", " Shape:", np.shape(Y_train_aug))
    print(f"Number of validation samples_K{current_fold}: {len(X_val)}", " Shape:", np.shape(X_val))
    print(f"Number of validation masks_K{current_fold}: {len(Y_val)}", " Shape:", np.shape(Y_val))
    print(f"Number of test samples_K{current_fold}: {len(X_test_fold)}", " Shape:", np.shape(X_test_fold))
    print(f"Number of test masks_K{current_fold}: {len(Y_test_fold)}", " Shape:", np.shape(Y_test_fold))

    # to check if every is looking fine (also check orientation)
    image_x = random.randint(0, len(X_train_aug)-1)

    plt.figure()
    plt.subplot(1,2,1)
    plt.imshow(np.squeeze(X_train_aug[image_x]), cmap='gray') # for grayscale images
    plt.subplot(1,2,2)
    plt.imshow(np.squeeze(Y_train_aug[image_x]), cmap='gray')
    plt.show()

    print(f"Shape of an augmented image: {np.shape(X_train_aug[image_x])}")

    ###################

    ### Model Architecture ###
    ### U-Net 9 ###
    
    def contracting_block(input, num_filters, dropout_rate):
        conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(input)
        conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)
        drop = tf.keras.layers.Dropout(dropout_rate)(conv)
        pool = tf.keras.layers.MaxPooling2D((2, 2))(drop)
        return drop, pool
    
    def expansive_block(input, skip_tensor, num_filters, dropout_rate):
        upsample = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input)
        concat = tf.keras.layers.concatenate([upsample, skip_tensor])
        conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat)
        conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)
        drop = tf.keras.layers.Dropout(dropout_rate)(conv)
        return drop
    
    # Input layer
    input_layer = tf.keras.layers.Input(shape=(SIZE, SIZE, IMG_CHANNELS))
    normalized = tf.keras.layers.Lambda(lambda x: x / 255.0)(input_layer)
    
    # Contracting path
    conv1, pool1 = contracting_block(normalized, NUM_FILTERS, DROPOUT_RATE)
    conv2, pool2 = contracting_block(pool1, NUM_FILTERS*2, DROPOUT_RATE)
    conv3, pool3 = contracting_block(pool2, NUM_FILTERS*4, DROPOUT_RATE)
    conv4, pool4 = contracting_block(pool3, NUM_FILTERS*8, DROPOUT_RATE)
    conv5, _ = contracting_block(pool4, NUM_FILTERS*16, DROPOUT_RATE)
    
    # Expansive path
    expan1 = expansive_block(conv5, conv4, NUM_FILTERS*8, DROPOUT_RATE)
    expan2 = expansive_block(expan1, conv3, NUM_FILTERS*4, DROPOUT_RATE)
    expan3 = expansive_block(expan2, conv2, NUM_FILTERS*2, DROPOUT_RATE)
    expan4 = expansive_block(expan3, conv1, NUM_FILTERS, DROPOUT_RATE)
    
    # Output layer
    final_output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(expan4)
    
    # Create model
    model = tf.keras.Model(inputs=[input_layer], outputs=[final_output])
    model.summary()

    ################################################################################

    # Define callbacks
    callbacks = [
        tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_f1_score', mode='max', restore_best_weights=True),
        tf.keras.callbacks.ModelCheckpoint(filepath=f'/content/drive/MyDrive/U-net/segmented_/Final_5fold_ES_Atrous_Decoder_1x1_U-net_9_K{fold}_200img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.keras',
                        monitor='val_f1_score', save_best_only=True, mode='max', verbose=1),
        tf.keras.callbacks.TensorBoard(log_dir='logs')
    ]

    # Compile the model
    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipvalue=CLIPVALUE)

    model.compile(optimizer=optimizer, loss='binary_crossentropy',
                  metrics=[accuracy_metric, precision_metric, recall_metric, f1_score, IoU])

    # Train the model
    results = model.fit(X_train_aug, Y_train_aug, batch_size=BATCH_SIZE, epochs=100,
                        validation_data=(X_val, Y_val), callbacks=callbacks)

    # Load the best saved model if needed
    best_model = tf.keras.models.load_model(f'/content/drive/MyDrive/U-net/segmented_/Final_5fold_ES_Atrous_Decoder_1x1_U-net_9_K{fold}_200img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.keras',
        safe_mode=False, custom_objects={'f1_score': f1_score, 'IoU':IoU})

    #######################################################################################

    ### validation image evaluation metrics ###
    def batch_predict(model, data, batch_size):
      predictions = []
      for i in range(0, len(data), batch_size):
          batch_data = data[i:i + batch_size]
          batch_predictions = model.predict(batch_data)
          predictions.append(batch_predictions)
      return np.concatenate(predictions, axis=0)

    # Make predictions in batches
    batch_size = 10  # Adjust batch size according to your GPU memory capacity
    prediction_test = batch_predict(best_model, X_test_fold, batch_size=batch_size)

    # Convert predictions to binary
    prediction_test_binary = prediction_test > 0.5

    # Calculate precision, recall, and F1 score
    accuracy_test = metrics.accuracy_score(Y_test_fold.flatten(), prediction_test_binary.flatten())
    Accuracy.append(accuracy_test)
    precision_test = metrics.precision_score(Y_test_fold.flatten(), prediction_test_binary.flatten(), average='binary')
    Precision.append(precision_test)
    recall_test = metrics.recall_score(Y_test_fold.flatten(), prediction_test_binary.flatten(), average='binary')
    Recall.append(recall_test)
    f1_test = metrics.f1_score(Y_test_fold.flatten(), prediction_test_binary.flatten(), average='binary')
    F1_score.append(f1_test)
    IoU_test = metrics.jaccard_score(Y_test_fold.flatten(), prediction_test_binary.flatten())
    IoU_scores.append(IoU_test)

    # Print out the results
    print(f'Accuracy_K{fold}: {accuracy_test:.4f}')
    print(f'Precision_K{fold}: {precision_test:.4f}')
    print(f'Recall_K{fold}: {recall_test:.4f}')
    print(f'F1 Score_K{fold}: {f1_test:.4f}')
    print(f'IoU_K{fold}: {IoU_test:.4f}')

    # Create a DataFrame from the training history and save to a Excel file
    history_df = pd.DataFrame(results.history)
    history_df.to_excel(f'/content/drive/MyDrive/U-net/segmented_/training_history_Final_5fold_ES_Atrous_Decoder_1x1_U-net_9_K{fold}_200img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.xlsx', index=False)

    # Plot the training F1 score and validation F1 score over epochs
    plt.figure(figsize=(12, 6))
    plt.plot(results.history['f1_score'], label='Training f1_score')
    plt.plot(results.history['val_f1_score'], label='Validation f1_score')
    plt.xlabel('Epochs')
    plt.ylabel('F1 score')
    plt.legend()
    plt.title('Training and Validation F1 scores Over Epochs')
    plt.show()

    # fold += 1
    current_fold += 1
Ave_Accuracy = sum(Accuracy) / 5
Ave_Precision = sum(Precision) / 5
Ave_Recall = sum(Recall) / 5
Ave_F1_score = sum(F1_score) / 5
Ave_IoU = sum(IoU_scores) / 5

SD_Accuracy = np.std(Accuracy)
SD_Precision = np.std(Precision)
SD_Recall = np.std(Recall)
SD_F1_score = np.std(F1_score)
SD_IoU = np.std(IoU_scores)

###################################################################

print(f'Final_5fold_ES_Atrous_Decoder_1x1_U-net_9_K{fold}_200img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}')
print(f'Average Accuracy: {Ave_Accuracy:.4f} ± {SD_Accuracy:.5f}')
print(f'Average Precision: {Ave_Precision:.4f} ± {SD_Precision:.5f}')
print(f'Average Recall: {Ave_Recall:.4f} ± {SD_Recall:.5f}')
print(f'Average F1 Score: {Ave_F1_score:.4f} ± {SD_F1_score:.5f}')
print(f'Average IoU: {Ave_IoU:.4f} ± {SD_IoU:.5f}')

def bootstrap_ci(data, num_iterations=10000, ci=95):
    data = np.array(data)
    boot_means = []
    for _ in range(num_iterations):
        sample = np.random.choice(data, size=len(data), replace=True)
        boot_means.append(np.mean(sample))

    lower = np.percentile(boot_means, (100 - ci) / 2)
    upper = np.percentile(boot_means, 100 - (100 - ci) / 2)
    mean = np.mean(boot_means)

    return mean, lower, upper

# Use raw fold values, not averages
mean_f1, ci_lower_f1, ci_upper_f1 = bootstrap_ci(F1_score)
mean_iou, ci_lower_iou, ci_upper_iou = bootstrap_ci(IoU_scores)

# Print results
print(f'Bootstrapped F1 Score: {mean_f1:.4f} (95% CI: {ci_lower_f1:.5f}–{ci_upper_f1:.5f})')
print(f'Bootstrapped IoU: {mean_iou:.4f} (95% CI: {ci_lower_iou:.5f}–{ci_upper_iou:.5f})')







