import tensorflow as tf
import os
import random
import numpy as np
from tqdm import tqdm
from skimage.io import imread, imshow
from skimage import img_as_ubyte, transform, util
import matplotlib.pyplot as plt
from PIL import Image
import csv
import pandas as pd
import openpyxl

# Ensure reproducibility
os.environ['TF_DETERMINISTIC_OPS'] = '1'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

np.random.seed(42)
random.seed(42)
tf.random.set_seed(42)

tf.config.threading.set_intra_op_parallelism_threads(1)
tf.config.threading.set_inter_op_parallelism_threads(1)

SIZE = 800
IMG_CHANNELS = 1

TRAIN_PATH = '/content/drive/MyDrive/U-net/train 120 refined/'
VAL_PATH = '/content/drive/MyDrive/U-net/validation 40 refined/'
TEST_PATH = '/content/drive/MyDrive/U-net/test 40 refined/'

# os.walk is used to get a list of subdirectories within the TRAIN_PATH and TEST_PATH directories,
# and the resulting subdirectory names are stored in train_ids and test_ids, respectively.
train_ids = next(os.walk(TRAIN_PATH))[1]   # [1] retrieves only the subdirectories within the current directory
val_ids = next(os.walk(VAL_PATH))[1]
test_ids = next(os.walk(TEST_PATH))[1]

# Define metrics
accuracy_metric = tf.keras.metrics.BinaryAccuracy()
precision_metric = tf.keras.metrics.Precision()
recall_metric = tf.keras.metrics.Recall()

def f1_score(y_true, y_pred):
    y_true = tf.keras.backend.cast(y_true, 'float32')
    y_pred = tf.keras.backend.cast(y_pred, 'float32')
    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))
    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))
    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))

    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())
    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())

    f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
    return f1


def IoU(y_true, y_pred):
    # Clip predictions and ground truths to binary values (0 or 1)
    y_true = tf.keras.backend.cast(y_true, 'float32')
    y_pred = tf.keras.backend.cast(y_pred, 'float32')

    y_true = tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1))
    y_pred = tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1))

    # Calculate the intersection and union
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection

    # Calculate IoU
    iou = intersection / (union + tf.keras.backend.epsilon())

    return iou

def adjust_contrast(image, contrast_factor):
    image = image.astype(np.float32)  # Convert image to float32 for precise computation
    mean = np.mean(image)
    return np.clip((image - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)

### Train Images ###

# store the preprocessed images and their corresponding binary masks
X_train = np.zeros((len(train_ids), SIZE, SIZE, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(train_ids), SIZE, SIZE, 1), dtype=bool)

print('Processing training data')

# Iterate through all the training IDs
for index, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):
    # Construct the paths for the image and mask
    img_path = f"{TRAIN_PATH}{id_}/image/{id_}.jpg"
    mask_path = f"{TRAIN_PATH}{id_}/mask/{id_}.png"

    # Load and normalize the image
    image = imread(img_path, as_gray=True)
    image = np.uint8(image)  # ensure the images to be 8-bit
    image = np.expand_dims(image, axis=-1)  # Ensure image has 3 dimensions
    X_train[index] = image

    # Load and prepare the mask
    mask = imread(mask_path, as_gray=True)
    mask = mask > 0  # Convert grayscale to binary mask
    mask = np.expand_dims(mask, axis=-1)  # Ensure mask has 3 dimensions
    Y_train[index] = mask


# Image augmentation for the training data
X_train_aug = []
Y_train_aug = []

for n in tqdm(range(len(X_train))):
    augmented_images = []
    augmented_masks = []

    for angle in [0, 90, 180, 270]:
        augmented_img_rotate = transform.rotate(X_train[n], angle, mode='reflect')
        augmented_mask_rotate = transform.rotate(Y_train[n], angle, mode='reflect')

        augmented_images.append(img_as_ubyte(augmented_img_rotate))  # img_as_ubyte: Convert to 8-bit uint.
        augmented_masks.append(augmented_mask_rotate > 0)  # Ensure masks remain binary

    augmented_images.extend([img_as_ubyte(np.fliplr(img)) for img in augmented_images])
    augmented_masks.extend([np.fliplr(mask) > 0 for mask in augmented_masks])  # Flip and convert masks to binary

    for img in augmented_images:
        contrast_factor = random.uniform(0.5, 1.5)  # Randomly choose a contrast factor between 0.5 and 1.5
        img_contrast = adjust_contrast(img, contrast_factor)
        X_train_aug.append(img_contrast)

    Y_train_aug.extend(augmented_masks)

X_train_aug = np.array(X_train_aug, dtype=np.uint8)
Y_train_aug = np.array(Y_train_aug, dtype=bool)

print("X_train_aug length: ", len(X_train_aug))
print("Y_train_aug length: ", len(Y_train_aug))

# validation images
X_val = np.zeros((len(val_ids), SIZE, SIZE, IMG_CHANNELS), dtype=np.uint8)
Y_val = np.zeros((len(val_ids), SIZE, SIZE, 1), dtype=bool)

print('Processing validation data')

# Iterate through all the training IDs
for index, id_ in tqdm(enumerate(val_ids), total=len(val_ids)):
    # Construct the paths for the image and mask
    img_path = f"{VAL_PATH}{id_}/image/{id_}.jpg"
    mask_path = f"{VAL_PATH}{id_}/mask/{id_}.png"

    # Load and normalize the image
    image = imread(img_path, as_gray=True)
    image = np.uint8(image)
    image = np.expand_dims(image, axis=-1)  # Ensure image has 3 dimensions
    X_val[index] = image

    # Load and prepare the mask
    mask = imread(mask_path, as_gray=True)
    mask = mask > 0  # Convert grayscale to binary mask
    mask = np.expand_dims(mask, axis=-1)  # Ensure mask has 3 dimensions
    Y_val[index] = mask

# test images
X_test = np.zeros((len(test_ids), SIZE, SIZE, IMG_CHANNELS), dtype=np.uint8)
Y_test = np.zeros((len(test_ids), SIZE, SIZE, 1), dtype=bool)

print('Processing testing data')

# Iterate through all the training IDs
for index, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):
    # Construct the paths for the image and mask
    img_path = f"{TEST_PATH}{id_}/image/{id_}.jpg"
    mask_path = f"{TEST_PATH}{id_}/mask/{id_}.png"

    # Load and normalize the image
    image = imread(img_path, as_gray=True)
    image = np.uint8(image)
    image = np.expand_dims(image, axis=-1)  # Ensure image has 3 dimensions
    X_test[index] = image

    # Load and prepare the mask
    mask = imread(mask_path, as_gray=True)
    mask = mask > 0  # Convert grayscale to binary mask
    mask = np.expand_dims(mask, axis=-1)  # Ensure mask has 3 dimensions
    Y_test[index] = mask

NUM_FILTERS = 24
DROPOUT_RATE = 0.2
LEARNING_RATE = 0.0005
CLIPVALUE = 1
BATCH_SIZE = 4

### Model Architecture ###
### U-Net 9 ###

def contracting_block(input, num_filters, dropout_rate):
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(input)
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)
    drop = tf.keras.layers.Dropout(dropout_rate)(conv)
    pool = tf.keras.layers.MaxPooling2D((2, 2))(drop)
    return drop, pool

def expansive_block(input, skip_tensor, num_filters, dropout_rate):
    upsample = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input)
    concat = tf.keras.layers.concatenate([upsample, skip_tensor])
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat)
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)
    drop = tf.keras.layers.Dropout(dropout_rate)(conv)
    return drop

# Input layer
input_layer = tf.keras.layers.Input(shape=(SIZE, SIZE, IMG_CHANNELS))
normalized = tf.keras.layers.Lambda(lambda x: x / 255.0)(input_layer)

# Contracting path
conv1, pool1 = contracting_block(normalized, NUM_FILTERS, DROPOUT_RATE)
conv2, pool2 = contracting_block(pool1, NUM_FILTERS*2, DROPOUT_RATE)
conv3, pool3 = contracting_block(pool2, NUM_FILTERS*4, DROPOUT_RATE)
conv4, pool4 = contracting_block(pool3, NUM_FILTERS*8, DROPOUT_RATE)
conv5, _ = contracting_block(pool4, NUM_FILTERS*16, DROPOUT_RATE)

# Expansive path
expan1 = expansive_block(conv5, conv4, NUM_FILTERS*8, DROPOUT_RATE)
expan2 = expansive_block(expan1, conv3, NUM_FILTERS*4, DROPOUT_RATE)
expan3 = expansive_block(expan2, conv2, NUM_FILTERS*2, DROPOUT_RATE)
expan4 = expansive_block(expan3, conv1, NUM_FILTERS, DROPOUT_RATE)

# Output layer
final_output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(expan4)

# Create model
model = tf.keras.Model(inputs=[input_layer], outputs=[final_output])
model.summary()

# Define callbacks
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=100, monitor='val_f1_score', mode='max', restore_best_weights=True),
    tf.keras.callbacks.ModelCheckpoint(filepath=f'/content/drive/MyDrive/U-net/segmented_/Final_Test_U-net_9_120img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.keras',
                    monitor='val_f1_score', save_best_only=True, mode='max', verbose=1),
    tf.keras.callbacks.TensorBoard(log_dir='logs')
]

# Compile the model
optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipvalue=CLIPVALUE)

model.compile(optimizer=optimizer, loss='binary_crossentropy',
              metrics=[accuracy_metric, precision_metric, recall_metric, f1_score, IoU])

# Train the model
results = model.fit(X_train_aug, Y_train_aug, batch_size=BATCH_SIZE, epochs=100,
                    validation_data=(X_val, Y_val), callbacks=callbacks)

# Load the best saved model if needed
best_model = tf.keras.models.load_model(f'/content/drive/MyDrive/U-net/segmented_/Final_Test_U-net_9_120img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.keras',
    safe_mode=False, custom_objects={'f1_score': f1_score, 'IoU':IoU})

### validation image evaluation metrics ###
def batch_predict(model, data, batch_size):
  predictions = []
  for i in range(0, len(data), batch_size):
      batch_data = data[i:i + batch_size]
      batch_predictions = model.predict(batch_data)
      predictions.append(batch_predictions)
  return np.concatenate(predictions, axis=0)

# Make predictions in batches
batch_size = 10  # Adjust batch size according to your GPU memory capacity
prediction_validation = batch_predict(best_model, X_test, batch_size=batch_size)

# Convert predictions to binary
prediction_validation_binary = prediction_validation > 0.5

# Calculate precision, recall, and F1 score
accuracy_validation = metrics.accuracy_score(Y_test.flatten(), prediction_validation_binary.flatten())
precision_validation = metrics.precision_score(Y_test.flatten(), prediction_validation_binary.flatten(), average='binary')
recall_validation = metrics.recall_score(Y_test.flatten(), prediction_validation_binary.flatten(), average='binary')
f1_validation = metrics.f1_score(Y_test.flatten(), prediction_validation_binary.flatten(), average='binary')
IoU_validation = metrics.jaccard_score(Y_test.flatten(), prediction_validation_binary.flatten())

# Print out the results
print(f'Final_Test_U-net_9_120img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}')
print(f'Accuracy: {accuracy_validation:.4f}')
print(f'Precision: {precision_validation:.4f}')
print(f'Recall: {recall_validation:.4f}')
print(f'F1 Score: {f1_validation:.4f}')
print(f'IoU: {IoU_validation:.4f}')

# Create a DataFrame from the training history and save to a Excel file
history_df = pd.DataFrame(results.history)
history_df.to_excel(f'/content/drive/MyDrive/U-net/segmented_/Final_Test_U-net_9_120img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.xlsx', index=False)
