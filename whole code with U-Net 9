import tensorflow as tf
import os
import random
import numpy as np
from tqdm import tqdm
from skimage.io import imread, imshow
from skimage import img_as_ubyte, transform, util
# from skimage.transform import resize
import matplotlib.pyplot as plt
from PIL import Image
import csv
import pandas as pd
import openpyxl


# Ensure reproducibility
os.environ['TF_DETERMINISTIC_OPS'] = '1'
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

np.random.seed(42)
random.seed(42)
tf.random.set_seed(42)

tf.config.threading.set_intra_op_parallelism_threads(1)
tf.config.threading.set_inter_op_parallelism_threads(1)

SIZE = 800
IMG_CHANNELS = 1

TRAIN_PATH = '/home/vcpuser/train 120 refined/'
TEST_PATH = '/home/vcpuser/test 80 refined/'

### Defines ###

precision_metric = tf.keras.metrics.Precision()
recall_metric = tf.keras.metrics.Recall()
accuracy_metric = tf.keras.metrics.BinaryAccuracy()

def f1_score(y_true, y_pred):
    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))
    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))
    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))

    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())
    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())

    f1 = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())
    return f1

def IoU(y_true, y_pred):
    # Clip predictions and ground truths to binary values (0 or 1)
    y_true = tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1))
    y_pred = tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1))
    
    # Calculate the intersection and union
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection
    
    # Calculate IoU
    iou = intersection / (union + tf.keras.backend.epsilon())
    
    return iou

def adjust_contrast(image, contrast_factor):
    image = image.astype(np.float32)  # Convert image to float32 for precise computation
    mean = np.mean(image)
    return np.clip((image - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)


### Train Images ###

train_ids = next(os.walk(TRAIN_PATH))[1]   
test_ids = next(os.walk(TEST_PATH))[1]
X_train = np.zeros((len(train_ids), SIZE, SIZE, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(train_ids), SIZE, SIZE, 1), dtype=bool)

# Iterate through all the training IDs
for index, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):
    # Construct the paths for the image and mask
    img_path = f"{TRAIN_PATH}{id_}/image/{id_}.jpg"
    mask_path = f"{TRAIN_PATH}{id_}/mask/{id_}.png"

    # Load and normalize the image
    image = imread(img_path, as_gray=True)
    image = np.uint8(image)  # ensure the images to be 8-bit
    image = np.expand_dims(image, axis=-1)  # Ensure image has 3 dimensions
    X_train[index] = image

    # Load and prepare the mask
    mask = imread(mask_path, as_gray=True)
    mask = mask > 0  # Convert grayscale to binary mask
    mask = np.expand_dims(mask, axis=-1)  # Ensure mask has 3 dimensions
    Y_train[index] = mask

# Image augmentation for the training data
X_train_aug = []
Y_train_aug = []

for n in tqdm(range(len(X_train))):
    augmented_images = []
    augmented_masks = []

    for angle in [0, 90, 180, 270]:
        augmented_img_rotate = transform.rotate(X_train[n], angle, mode='reflect')
        augmented_mask_rotate = transform.rotate(Y_train[n], angle, mode='reflect')

        augmented_images.append(img_as_ubyte(augmented_img_rotate))  # img_as_ubyte: Convert to 8-bit uint.
        augmented_masks.append(augmented_mask_rotate > 0)  # Ensure masks remain binary

    augmented_images.extend([img_as_ubyte(np.fliplr(img)) for img in augmented_images])
    augmented_masks.extend([np.fliplr(mask) > 0 for mask in augmented_masks])  # Flip and convert masks to binary

    for img in augmented_images:
        contrast_factor = random.uniform(0.5, 1.5) # Randomly choose a contrast factor between 0.5 and 1.5
        img_contrast = adjust_contrast(img, contrast_factor)
        X_train_aug.append(img_contrast)

    Y_train_aug.extend(augmented_masks)

X_train_aug = np.array(X_train_aug, dtype=np.uint8)
Y_train_aug = np.array(Y_train_aug, dtype=bool)

print("X_train_aug length: ", len(X_train_aug))
print("Y_train_aug length: ", len(Y_train_aug))

#### test images ###
X_test = np.zeros((len(test_ids), SIZE, SIZE, IMG_CHANNELS), dtype=np.uint8)
Y_test = np.zeros((len(test_ids), SIZE, SIZE, 1), dtype=bool)

print('Processing testing data')

# Iterate through all the training IDs
for index, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):
    # Construct the paths for the image and mask
    img_path = f"{TEST_PATH}{id_}/image/{id_}.jpg"
    mask_path = f"{TEST_PATH}{id_}/mask/{id_}.png"

    # Load and normalize the image
    image = imread(img_path, as_gray=True)
    image = np.uint8(image)
    image = np.expand_dims(image, axis=-1)  # Ensure image has 3 dimensions
    X_test[index] = image

    # Load and prepare the mask
    mask = imread(mask_path, as_gray=True)
    mask = mask > 0  # Convert grayscale to binary mask
    mask = np.expand_dims(mask, axis=-1)  # Ensure mask has 3 dimensions
    Y_test[index] = mask
    
print("X_test length: ", len(X_test))
print("Y_test length: ", len(Y_test))

### Hyperparameters ###

NUM_FILTERS = 24
DROPOUT_RATE = 0.2
LEARNING_RATE = 0.0005
CLIPVALUE = 1
BATCH_SIZE = 4

### Model Architecture ###
### Basic U-Net 9 ###

def contracting_block(input, num_filters, dropout_rate):
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(input)
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)
    drop = tf.keras.layers.Dropout(dropout_rate)(conv)
    pool = tf.keras.layers.MaxPooling2D((2, 2))(drop)
    return drop, pool

def expansive_block(input, skip_tensor, num_filters, dropout_rate):
    upsample = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input)
    concat = tf.keras.layers.concatenate([upsample, skip_tensor])
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(concat)
    conv = tf.keras.layers.Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv)
    drop = tf.keras.layers.Dropout(dropout_rate)(conv)
    return drop

# Input layer
input_layer = tf.keras.layers.Input(shape=(SIZE, SIZE, IMG_CHANNELS))
normalized = tf.keras.layers.Lambda(lambda x: x / 255.0)(input_layer)

# Contracting path
conv1, pool1 = contracting_block(normalized, NUM_FILTERS, DROPOUT_RATE)
conv2, pool2 = contracting_block(pool1, NUM_FILTERS*2, DROPOUT_RATE)
conv3, pool3 = contracting_block(pool2, NUM_FILTERS*4, DROPOUT_RATE)
conv4, pool4 = contracting_block(pool3, NUM_FILTERS*8, DROPOUT_RATE)
conv5, _ = contracting_block(pool4, NUM_FILTERS*16, DROPOUT_RATE)

# Expansive path
expan1 = expansive_block(conv5, conv4, NUM_FILTERS*8, DROPOUT_RATE)
expan2 = expansive_block(expan1, conv3, NUM_FILTERS*4, DROPOUT_RATE)
expan3 = expansive_block(expan2, conv2, NUM_FILTERS*2, DROPOUT_RATE)
expan4 = expansive_block(expan3, conv1, NUM_FILTERS, DROPOUT_RATE)

# Output layer
final_output = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(expan4)

# Create model
model = tf.keras.Model(inputs=[input_layer], outputs=[final_output])
model.summary()

callbacks = [
tf.keras.callbacks.EarlyStopping(patience=100, monitor='val_f1_score', mode='max', restore_best_weights=True),
tf.keras.callbacks.TensorBoard(log_dir='logs')
]

optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE, clipvalue=CLIPVALUE)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[accuracy_metric, precision_metric, recall_metric, f1_score, IoU])
results = model.fit(X_train_aug, Y_train_aug, batch_size=BATCH_SIZE, epochs=100, validation_data=(X_test, Y_test), callbacks=callbacks)

# Save the trained model
model.save(f'/home/vcpuser/Final segmented_/Final_Test_Basic_U-net_9_120img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.keras')

# Create a DataFrame from the training history and save to a Excel file
history_df = pd.DataFrame(results.history)
history_df.to_excel(f'/home/vcpuser/Final segmented_/Final_Test_Basic_U-net_9_120img_filter{NUM_FILTERS}_Drop{DROPOUT_RATE}_LR{LEARNING_RATE}_clip{CLIPVALUE}_batchsize{BATCH_SIZE}.xlsx', index=False)
